"""
å®Œæ•´æ¸¬è©¦æ‰€æœ‰æ–°èçˆ¬èŸ² (ORMç‰ˆæœ¬)
"""

import sys
import os
from datetime import datetime

# æ·»åŠ  scrapying ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), 'scrapying'))

from setn_new import SETNScraper
from ltn_scraper_orm import LTNScraper
from tvbs_scraper_orm import TVBSScraper
from chinatimes_scraper_orm import ChinaTimesScraper

from models import News
from database_orm import get_db_session


def test_all_scrapers():
    """æ¸¬è©¦æ‰€æœ‰çˆ¬èŸ²"""
    print("ğŸš€ æ–°èçˆ¬èŸ²ç³»çµ±å®Œæ•´æ¸¬è©¦")
    print("=" * 50)
    print(f"æ¸¬è©¦æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    scrapers = [
        ("SETN ä¸‰ç«‹æ–°è", SETNScraper()),
        ("LTN è‡ªç”±æ™‚å ±", LTNScraper()),
        ("TVBS æ–°è", TVBSScraper()),
        ("ChinaTimes ä¸­æ™‚", ChinaTimesScraper())
    ]
    
    results = {}
    total_news = 0
    
    for name, scraper in scrapers:
        print(f"ğŸ“° æ¸¬è©¦ {name}")
        print("-" * 30)
        
        try:
            # é™åˆ¶æ¯å€‹çˆ¬èŸ²çˆ¬å–1é åšæ¸¬è©¦
            result = scraper.scrape_news(max_pages=1)
            
            results[name] = result
            total_news += result['new']
            
            print(f"âœ… {name} æ¸¬è©¦å®Œæˆ")
            print(f"   ç¸½è¨ˆ: {result['total']}")
            print(f"   æ–°å¢: {result['new']}")
            print(f"   è·³é: {result['skipped']}")
            print(f"   å¤±æ•—: {result['failed']}")
            print()
            
        except Exception as e:
            print(f"âŒ {name} æ¸¬è©¦å¤±æ•—: {e}")
            results[name] = {'error': str(e)}
            print()
    
    # ç¸½çµå ±å‘Š
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ")
    print("=" * 50)
    
    # æŸ¥è©¢è³‡æ–™åº«ç‹€æ…‹
    with get_db_session() as session:
        for name, scraper in scrapers:
            source = scraper.news_source
            count = session.query(News).filter(News.news_source == source).count()
            
            if name in results and 'error' not in results[name]:
                status = "âœ… æ­£å¸¸"
                new_count = results[name]['new']
                print(f"{source:12}: {count:3d} ç­† ({new_count:2d} æ–°å¢) {status}")
            else:
                status = "âŒ ç•°å¸¸"
                print(f"{source:12}: {count:3d} ç­†              {status}")
        
        total_in_db = session.query(News).count()
        print(f"\nğŸ“ˆ è³‡æ–™åº«ç¸½è¨ˆ: {total_in_db} ç­†æ–°è")
        print(f"ğŸ†• æœ¬æ¬¡æ–°å¢: {total_news} ç­†")
    
    # æª¢æŸ¥æ—¥æœŸæ ¼å¼çµ±ä¸€æ€§
    print("\nğŸ• æ—¥æœŸæ ¼å¼æª¢æŸ¥")
    print("-" * 30)
    
    with get_db_session() as session:
        sources = ['SETN', 'LTN', 'TVBS', 'ChinaTimes']
        for source in sources:
            news = session.query(News).filter(News.news_source == source).first()
            if news:
                print(f"{source:12}: {news.publish_time} âœ“")
            else:
                print(f"{source:12}: ç„¡è³‡æ–™")
    
    print("\nğŸ‰ æ¸¬è©¦å®Œæˆï¼æ‰€æœ‰çˆ¬èŸ²éƒ½ä½¿ç”¨çµ±ä¸€çš„æ—¥æœŸæ ¼å¼ (YYYY-MM-DD HH:MM:SS)")


if __name__ == "__main__":
    test_all_scrapers()
