#!/usr/bin/env python3
"""
æ–°è API æ‡‰ç”¨ - ä½¿ç”¨åˆ†é›¢çš„æ’ç¨‹å™¨ (MongoDB ç‰ˆæœ¬)
"""

from fastapi import FastAPI, HTTPException, Query, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
import logging
import os
from contextlib import asynccontextmanager
from pydantic import BaseModel
from dotenv import load_dotenv

# åŒ¯å…¥ MongoDB ç›¸é—œæ¨¡çµ„
from db.database_mongodb import init_mongodb, close_mongodb, get_mongodb_connection
from db.news_mongodb import get_news_mongo_db

# åŒ¯å…¥åˆ†é›¢çš„æ’ç¨‹å™¨
from .scheduler import start_scheduler, stop_scheduler, get_scheduler_status, get_scheduler_interval, run_scraper_job

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šæ—¥èªŒ
from logging.handlers import TimedRotatingFileHandler
from pathlib import Path

LOG_DIR = Path("logs")
LOG_DIR.mkdir(exist_ok=True)

logger = logging.getLogger("news_api")
logger.setLevel(logging.INFO)

# æ¸…é™¤ç¾æœ‰çš„ handlers
for handler in logger.handlers[:]:
    logger.removeHandler(handler)

# è¨­å®šæ ¼å¼
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# æ™‚é–“è¼ªè½‰æ–‡ä»¶è™•ç†å™¨
file_handler = TimedRotatingFileHandler(
    filename=LOG_DIR / "api.log",
    when='midnight',
    interval=1,
    backupCount=7,
    encoding='utf-8'
)
file_handler.setFormatter(formatter)
file_handler.suffix = "%Y%m%d"

# æ§åˆ¶å°è™•ç†å™¨
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)

# æ·»åŠ è™•ç†å™¨
logger.addHandler(file_handler)
logger.addHandler(console_handler)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """æ‡‰ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å•Ÿå‹•æ™‚
    logger.info("ğŸš€ æ–°è API æœå‹™å•Ÿå‹• (MongoDBç‰ˆæœ¬)")
    
    # åˆå§‹åŒ– MongoDB é€£æ¥
    try:
        if not init_mongodb():
            logger.error("MongoDB é€£æ¥å¤±æ•—")
            raise RuntimeError("ç„¡æ³•é€£æ¥åˆ° MongoDB")
        logger.info("ğŸ“¦ MongoDB é€£æ¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"MongoDB åˆå§‹åŒ–å¤±æ•—: {e}")
        raise
    
    # å•Ÿå‹•æ’ç¨‹å™¨
    interval = get_scheduler_interval()
    await start_scheduler(interval)
    logger.info(f"ğŸ“… æ’ç¨‹å™¨å·²å•Ÿå‹• - æ¯ {interval} å°æ™‚åŸ·è¡Œçˆ¬èŸ²")
    
    yield
    
    # é—œé–‰æ™‚
    logger.info("ğŸ‘‹ æ­£åœ¨é—œé–‰æ–°è API æœå‹™")
    await stop_scheduler()
    close_mongodb()

app = FastAPI(
    title="æ–°è API with Scheduler (MongoDB)",
    description="æä¾›æ–°èæ•¸æ“šçš„ RESTful APIï¼Œå…§å»ºè‡ªå‹•çˆ¬èŸ²æ’ç¨‹ (ä½¿ç”¨ MongoDB)",
    version="2.0.0-mongodb",
    lifespan=lifespan
)

# æ·»åŠ  CORS ä¸­é–“ä»¶ï¼Œæ”¯æŒå‰ç«¯è·¨åŸŸè«‹æ±‚
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒä¸­æ‡‰è©²æŒ‡å®šå…·é«”çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MongoDB ä¾è³´æ³¨å…¥
def get_mongo_db():
    """ç²å– MongoDB é€£æ¥"""
    connection = get_mongodb_connection()
    if not connection.is_connected():
        raise HTTPException(status_code=503, detail="MongoDB é€£æ¥ä¸å¯ç”¨")
    return get_news_mongo_db()

# Pydantic æ¨¡å‹
class NewsResponse(BaseModel):
    pk: str  # MongoDB ObjectId ä½œç‚ºå­—ä¸²
    news_id: str
    news_source: str
    author: Optional[str] = None
    title: Optional[str] = None
    url: Optional[str] = None
    publish_time: Optional[str] = None
    create_time: Optional[datetime] = None

class NewsListResponse(BaseModel):
    total: int
    page: int
    per_page: int
    pages: int
    data: List[NewsResponse]

class StatsResponse(BaseModel):
    total_news: int
    sources: Dict[str, int]
    latest_update: Optional[datetime] = None

class SchedulerStatusResponse(BaseModel):
    status: str
    interval_hours: int
    next_run: Optional[datetime] = None
    last_run: Optional[datetime] = None

# API è·¯ç”±
@app.get("/")
async def root():
    """æ ¹è·¯ç”±"""
    interval = get_scheduler_interval()
    return {
        "message": "æ–°è API æœå‹™å™¨ with Scheduler",
        "version": "2.0.0",
        "docs": "/docs",
        "scheduler": {
            "enabled": True,
            "interval_hours": interval
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    try:
        # æ¸¬è©¦ MongoDB é€£æ¥
        connection = get_mongodb_connection()
        if not connection.is_connected():
            raise HTTPException(status_code=503, detail="MongoDB é€£æ¥ä¸å¯ç”¨")
        
        # ç²å–æ’ç¨‹å™¨ç‹€æ…‹
        scheduler_status = get_scheduler_status()
        
        # ç²å– MongoDB è³‡æ–™åº«è³‡è¨Š
        db_info = connection.get_database_info()
        
        return {
            "status": "healthy",
            "database": "connected",
            "database_info": {
                "type": "MongoDB",
                "collections": db_info.get("collections_count", 0),
                "data_size": db_info.get("data_size", 0)
            },
            "scheduler": scheduler_status["status"],
            "timestamp": datetime.now()
        }
    except Exception as e:
        logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
        raise HTTPException(status_code=503, detail="æœå‹™æš«æ™‚ä¸å¯ç”¨")

@app.post("/scraper/run")
async def run_scraper_manually(background_tasks: BackgroundTasks):
    """æ‰‹å‹•åŸ·è¡Œçˆ¬èŸ²"""
    try:
        background_tasks.add_task(run_scraper_job)
        logger.info("ğŸ”„ æ‰‹å‹•çˆ¬èŸ²ä»»å‹™å·²åŠ å…¥èƒŒæ™¯åŸ·è¡Œ")
        
        return {
            "message": "çˆ¬èŸ²ä»»å‹™å·²é–‹å§‹åŸ·è¡Œ",
            "status": "running",
            "timestamp": datetime.now()
        }
    except Exception as e:
        logger.error(f"æ‰‹å‹•åŸ·è¡Œçˆ¬èŸ²å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç„¡æ³•åŸ·è¡Œçˆ¬èŸ²ä»»å‹™")

@app.get("/scheduler/status")
async def get_scheduler_status_api():
    """ç²å–æ’ç¨‹å™¨ç‹€æ…‹"""
    try:
        status_info = get_scheduler_status()
        interval = get_scheduler_interval()
        
        # è¨ˆç®—ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“
        now = datetime.now()
        if interval == 24:
            next_run = now.replace(hour=2, minute=0, second=0, microsecond=0)
            if next_run <= now:
                next_run += timedelta(days=1)
        else:
            next_run = now + timedelta(hours=interval)
        
        return {
            "status": status_info["status"],
            "interval_hours": interval,
            "next_run": next_run,
            "last_run": None  # TODO: å¯¦ä½œä¸Šæ¬¡åŸ·è¡Œæ™‚é–“è¿½è¹¤
        }
    except Exception as e:
        logger.error(f"ç²å–æ’ç¨‹å™¨ç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç„¡æ³•ç²å–æ’ç¨‹å™¨ç‹€æ…‹")

@app.get("/news", response_model=NewsListResponse)
async def get_news(
    page: int = Query(1, ge=1, description="é ç¢¼"),
    per_page: int = Query(20, ge=1, le=100, description="æ¯é æ•¸é‡"),
    source: Optional[str] = Query(None, description="æ–°èä¾†æºéæ¿¾ (SETN, LTN, TVBS, ChinaTimes)"),
    search: Optional[str] = Query(None, description="æ¨™é¡Œæœå°‹é—œéµå­—"),
    author: Optional[str] = Query(None, description="ä½œè€…éæ¿¾"),
    start_date: Optional[str] = Query(None, description="é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)"),
    end_date: Optional[str] = Query(None, description="çµæŸæ—¥æœŸ (YYYY-MM-DD)"),
    sort_by: str = Query("create_time", description="æ’åºæ¬„ä½ (create_time, publish_time, title)"),
    sort_order: str = Query("desc", description="æ’åºæ–¹å‘ (asc, desc)"),
    mongo_db = Depends(get_mongo_db)
):
    """ç²å–æ–°èåˆ—è¡¨ - æ”¯æŒå¤šç¨®éæ¿¾å’Œæ’åºåŠŸèƒ½"""
    try:
        # ä½¿ç”¨ MongoDB æŸ¥è©¢
        result = mongo_db.get_news_by_query(
            page=page,
            per_page=per_page,
            news_source=source,
            search=search,
            author=author,
            start_date=start_date,
            end_date=end_date,
            sort_by=sort_by,
            sort_order=sort_order
        )
        
        # è½‰æ›ç‚ºéŸ¿æ‡‰æ¨¡å‹
        news_data = []
        for news_dict in result['data']:
            # è§£æ create_time å­—ä¸²ç‚º datetime å°è±¡
            create_time = None
            if news_dict.get('create_time'):
                try:
                    if isinstance(news_dict['create_time'], str):
                        create_time = datetime.fromisoformat(news_dict['create_time'].replace('Z', '+00:00'))
                    else:
                        create_time = news_dict['create_time']
                except:
                    create_time = None
            
            news_item = NewsResponse(
                pk=news_dict.get('pk', ''),
                news_id=news_dict.get('news_id', ''),
                news_source=news_dict.get('news_source', ''),
                author=news_dict.get('author'),
                title=news_dict.get('title'),
                url=news_dict.get('url'),
                publish_time=news_dict.get('publish_time'),
                create_time=create_time
            )
            news_data.append(news_item)
        
        return NewsListResponse(
            total=result['total'],
            page=result['page'],
            per_page=result['per_page'],
            pages=result['pages'],
            data=news_data
        )
        
    except Exception as e:
        logger.error(f"ç²å–æ–°èåˆ—è¡¨å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç²å–æ–°èåˆ—è¡¨å¤±æ•—")

@app.get("/stats", response_model=StatsResponse)
async def get_stats(mongo_db = Depends(get_mongo_db)):
    """ç²å–çµ±è¨ˆä¿¡æ¯"""
    try:
        # ä½¿ç”¨ MongoDB ç²å–çµ±è¨ˆè³‡è¨Š
        stats = mongo_db.get_stats()
        
        return StatsResponse(
            total_news=stats['total_news'],
            sources=stats['sources'],
            latest_update=stats['latest_update']
        )
        
    except Exception as e:
        logger.error(f"ç²å–çµ±è¨ˆä¿¡æ¯å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç²å–çµ±è¨ˆä¿¡æ¯å¤±æ•—")

@app.get("/news/recent")
async def get_recent_news(
    limit: int = Query(10, ge=1, le=50, description="è¿”å›æ•¸é‡"),
    source: Optional[str] = Query(None, description="æ–°èä¾†æºéæ¿¾"),
    sort_by: str = Query("create_time", description="æ’åºæ¬„ä½"),
    mongo_db = Depends(get_mongo_db)
):
    """ç²å–æœ€æ–°æ–°è"""
    try:
        # å¦‚æœæœ‰ä¾†æºéæ¿¾ï¼Œä½¿ç”¨æŸ¥è©¢åŠŸèƒ½
        if source:
            result = mongo_db.get_news_by_query(
                page=1,
                per_page=limit,
                news_source=source,
                sort_by=sort_by,
                sort_order="desc"
            )
            news_data = result['data']
        else:
            # ç›´æ¥ç²å–æœ€æ–°æ–°è
            news_data = mongo_db.get_recent_news(limit)
        
        # è½‰æ›æ ¼å¼ä»¥ç¬¦åˆåŸ API éŸ¿æ‡‰
        formatted_data = []
        for news_dict in news_data:
            # è§£æ create_time
            create_time = None
            if news_dict.get('create_time'):
                try:
                    if isinstance(news_dict['create_time'], str):
                        create_time = datetime.fromisoformat(news_dict['create_time'].replace('Z', '+00:00'))
                    else:
                        create_time = news_dict['create_time']
                except:
                    create_time = None
            
            formatted_data.append({
                "pk": news_dict.get('pk', ''),
                "news_id": news_dict.get('news_id', ''),
                "title": news_dict.get('title', ''),
                "url": news_dict.get('url', ''),
                "news_source": news_dict.get('news_source', ''),
                "author": news_dict.get('author', ''),
                "publish_time": news_dict.get('publish_time'),
                "create_time": create_time
            })
        
        return {
            "count": len(formatted_data),
            "data": formatted_data
        }
        
    except Exception as e:
        logger.error(f"ç²å–æœ€æ–°æ–°èå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç²å–æœ€æ–°æ–°èå¤±æ•—")

@app.get("/news/sources")
async def get_news_sources(mongo_db = Depends(get_mongo_db)):
    """ç²å–æ‰€æœ‰æ–°èä¾†æºåˆ—è¡¨"""
    try:
        sources_data = mongo_db.get_news_count_by_source()
        sources = []
        
        for source_name, count in sources_data:
            sources.append({
                "name": source_name,
                "count": count,
                "display_name": {
                    "SETN": "ä¸‰ç«‹æ–°è",
                    "LTN": "è‡ªç”±æ™‚å ±",
                    "TVBS": "TVBSæ–°è",
                    "ChinaTimes": "ä¸­æ™‚æ–°è"
                }.get(source_name, source_name)
            })
        
        return {
            "sources": sources,
            "total_sources": len(sources)
        }
        
    except Exception as e:
        logger.error(f"ç²å–æ–°èä¾†æºå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç²å–æ–°èä¾†æºå¤±æ•—")

@app.get("/news/search")
async def search_news(
    q: str = Query(..., description="æœå°‹é—œéµå­—"),
    page: int = Query(1, ge=1, description="é ç¢¼"),
    per_page: int = Query(20, ge=1, le=50, description="æ¯é æ•¸é‡"),
    source: Optional[str] = Query(None, description="æ–°èä¾†æºéæ¿¾"),
    sort_by: str = Query("create_time", description="æ’åºæ¬„ä½"),
    sort_order: str = Query("desc", description="æ’åºæ–¹å‘"),
    mongo_db = Depends(get_mongo_db)
):
    """æœå°‹æ–°è"""
    try:
        result = mongo_db.get_news_by_query(
            page=page,
            per_page=per_page,
            news_source=source,
            search=q,
            sort_by=sort_by,
            sort_order=sort_order
        )
        
        # è½‰æ›ç‚ºéŸ¿æ‡‰æ ¼å¼
        news_data = []
        for news_dict in result['data']:
            create_time = None
            if news_dict.get('create_time'):
                try:
                    if isinstance(news_dict['create_time'], str):
                        create_time = datetime.fromisoformat(news_dict['create_time'].replace('Z', '+00:00'))
                    else:
                        create_time = news_dict['create_time']
                except:
                    create_time = None
            
            news_item = NewsResponse(
                pk=news_dict.get('pk', ''),
                news_id=news_dict.get('news_id', ''),
                news_source=news_dict.get('news_source', ''),
                author=news_dict.get('author'),
                title=news_dict.get('title'),
                url=news_dict.get('url'),
                publish_time=news_dict.get('publish_time'),
                create_time=create_time
            )
            news_data.append(news_item)
        
        return NewsListResponse(
            total=result['total'],
            page=result['page'],
            per_page=result['per_page'],
            pages=result['pages'],
            data=news_data
        )
        
    except Exception as e:
        logger.error(f"æœå°‹æ–°èå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="æœå°‹æ–°èå¤±æ•—")

@app.get("/news/{news_id}")
async def get_news_detail(
    news_id: str,
    mongo_db = Depends(get_mongo_db)
):
    """ç²å–å–®æ¢æ–°èè©³æƒ…"""
    try:
        from bson import ObjectId
        from db.models_mongodb import News
        
        # é©—è­‰ ObjectId æ ¼å¼
        try:
            obj_id = ObjectId(news_id)
        except:
            raise HTTPException(status_code=400, detail="ç„¡æ•ˆçš„æ–°èIDæ ¼å¼")
        
        # æ ¹æ“š ObjectId æŸ¥æ‰¾
        news = News.objects(id=obj_id).first()
        if not news:
            raise HTTPException(status_code=404, detail="æ–°èæœªæ‰¾åˆ°")
        
        news_dict = news.to_dict()
        create_time = None
        if news_dict.get('create_time'):
            try:
                if isinstance(news_dict['create_time'], str):
                    create_time = datetime.fromisoformat(news_dict['create_time'].replace('Z', '+00:00'))
                else:
                    create_time = news_dict['create_time']
            except:
                create_time = None
        
        return NewsResponse(
            pk=news_dict.get('pk', ''),
            news_id=news_dict.get('news_id', ''),
            news_source=news_dict.get('news_source', ''),
            author=news_dict.get('author'),
            title=news_dict.get('title'),
            url=news_dict.get('url'),
            publish_time=news_dict.get('publish_time'),
            create_time=create_time
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç²å–æ–°èè©³æƒ…å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail="ç²å–æ–°èè©³æƒ…å¤±æ•—")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
